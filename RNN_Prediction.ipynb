{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billptw/SIH19-RNN-Epidemiological-Prediction/blob/master/RNN_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poZhQUmfVSVw",
        "colab_type": "code",
        "outputId": "52570ba9-b24c-4308-fb73-a3f2ac0ce8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My\\ Drive/CE7454_Group_38/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/CE7454_Group_38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPM2GeS5O7LD",
        "colab_type": "text"
      },
      "source": [
        "# **1. Problem Motivation**\n",
        "*   It is not uncommon that searches of a particular disease tend to spike at the initial onset of an outbreak\n",
        "*   Google has been the go-to search engine over the past decade. Hence, there is a question as to how effective trends of searches can be used to predict a disease outbreak\n",
        "*   These trend searches data can be used to train advanced predictive model like deep learning methods\n",
        "*   Ultimately, an accurate predictive model can be used to help countries like India with big land massess to do advance medical resource allocation\n",
        "*   In this project, we aim to use RNN-based models to predict weekly trend searches of diseases. The model will train on historical search trend data\n",
        "*   A model will be trained for each Indian state\n",
        "\n",
        "# **2. Data Acquisition**\n",
        "*   Collecting data via Pytrend's API for Google Search\n",
        "*   We scrape search trend data on \"**flu**\" for each state in India between 2012 to 2019\n",
        "*   For each state, a .csv file is generated with weekly search trends between 2012 to 2019\n",
        "*   The order of the number of unique data points per state ranges from tenth to hundredth making it extremely small\n",
        "\n",
        "# **3. Data Exploration**\n",
        "*   Google only provides relative search values (between 0-100), hence more data preprocessing is required in subsequent sections\n",
        "*   We go through the scraping year by year from 2012 to 2019. This means that the data is rescaled by Google within a year\n",
        "*   Each data point represents the total searches of the week (i.e. weekly data)\n",
        "*   Not every state have the same number of unique data points\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im2ZUHx3Prgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pytrends.request import TrendReq\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "look_back = 4\n",
        "bsz = 64\n",
        "epochs = 5000\n",
        "n_hidden = 32\n",
        "years = []\n",
        "#list_of_states = ['IN-TN', 'IN-KL', 'IN-KA', 'IN-AP', 'IN-GA', 'IN-MH','IN-CT','IN-OR','IN-MP','IN-GJ','IN-RJ','IN-UP','IN-JH','IN-WB','IN-BR','IN-HR','IN-PB','IN-HP','IN-JK','IN-UT','IN-SK','IN-ML','IN-AS','IN-AR','IN-NL','IN-MZ','IN-TR','IN-MN','IN-AN','IN-DL','IN-CH','IN-DD','IN-PY','IN-TG','IN-DN'],'IN-ML','IN-AS','IN-AR','IN-NL','IN-MZ','IN-TR','IN-MN','IN-AN','IN-DL','IN-CH','IN-DD','IN-PY','IN-TG','IN-DN']\n",
        "list_of_states = ['IN-BR','IN-HR','IN-PB','IN-HP','IN-JK','IN-UT','IN-SK','IN-ML','IN-AS','IN-AR','IN-NL','IN-MZ','IN-TR','IN-MN','IN-AN','IN-DL','IN-CH','IN-DD','IN-PY','IN-TG','IN-DN']\n",
        "pytrends = TrendReq(hl='en-US', tz=360)\n",
        "#pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), proxies=['https://34.203.233.13:80',], retries=2, backoff_factor=0.1)\n",
        "start = 12\n",
        "end = 19\n",
        "for i in tqdm(range(len(list_of_states))):\n",
        "    date1 = '20' + str(start) + '-01-01'\n",
        "    date2 = '20' + str(start) + '-12-31'\n",
        "    kw_list = [\"flu\"]\n",
        "    time_frame = date1 + ' ' + date2\n",
        "    pytrends.build_payload(kw_list, cat=0, timeframe=time_frame, geo=list_of_states[i], gprop='')\n",
        "    total_per_state = pytrends.interest_over_time()\n",
        "    for j in range(start+1, end):\n",
        "        date1 = '20' + str(j) + '-01-01'\n",
        "        date2 = '20' + str(j) + '-12-31'\n",
        "        kw_list = [\"flu\"]\n",
        "        time_frame = date1 + ' ' + date2\n",
        "        pytrends.build_payload(kw_list, cat=0, timeframe=time_frame, geo=list_of_states[i], gprop='')\n",
        "        temp = pytrends.interest_over_time()\n",
        "        total_per_state = pd.concat([total_per_state, temp], axis=0)\n",
        "    total_per_state.to_csv(r'' + list_of_states[i] + str(start) + '_' + str(end-1) +'.csv')\n",
        "    date1 = '20' + str(end-1) + '-12-09'\n",
        "    date2 = '20' + str(end) + '-12-31'\n",
        "    kw_list = [\"flu\"]\n",
        "    time_frame = date1 + ' ' + date2\n",
        "    pytrends.build_payload(kw_list, cat=0, timeframe=time_frame, geo=list_of_states[i], gprop='')\n",
        "    temp = pytrends.interest_over_time()\n",
        "    temp.to_csv(r'' + list_of_states[i] + str(end) +'.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkOD_edOQ8od",
        "colab_type": "text"
      },
      "source": [
        "# **4. Preprocessing and Packing of Data**\n",
        "*   As mentioned, data are scaled relative to the whole year. Hence, there is no way to recover absolute value of the searches\n",
        "*   The most useful thing that can be done is to do a prediction relative to the past 5 weeks \n",
        "*   This can then give an idea of how bad the searches is going to be in the coming week\n",
        "*   Hence, each data point is packed as an input (X) of 5 weeks and a label (Y) of the 6th week.\n",
        "*   Since the focus is on the relative magnitude among the 6 weeks considered, we do a min-max scaling among the 6 weeks for the train data per data instance\n",
        "\n",
        " >$X_{scaled} = \\frac{X - X_{min}}{X_{max}-X_{min}}$\n",
        "\n",
        " *where $X_{min}$, $X_{max}$ and $X_{scaled}$ are the minimum, maximum and scaled values of each of the data points within the each 6 weeks window frame* \n",
        "\n",
        "\n",
        "*   A training instance for each Indian state is generated by rolling a 6 weeks window forward by 1 week through the time-series data\n",
        "*   The data is arbitarily split between a train and test set. We train on data from 2012 to 2018 and test on the data of 2019\n",
        "\n",
        "\n",
        "# **5. Initialise and Training the Deep Learning Model**\n",
        "*   The output is a prediction of the 6th week trend relative to an input of the past 5 weeks\n",
        "*   We train a model for each state, hence if we have 30 states, then we would have 30 neural network models.\n",
        "*   Note that we added a fully connected layer to combine all the previous prediction of the LSTM rather than just taking the last term\n",
        "*   We train with mini-batches of batch size 64 for some predefined epoch. The maximum number of epoch was determined from visual inspection from the loss curve\n",
        "*   We observed that on the average across all the Indian states, loss plateaus after around 300 epoch. Thus, we set the maximum epoch to be 500 just to be safe\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK77rk__NxNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# LSTM Model Definition\n",
        "class Flu_LSTM(nn.Module):\n",
        "    def __init__(self, in_size, n_hidden, look_back, n_layers=2):\n",
        "        super(Flu_LSTM, self).__init__()\n",
        "        self.out = 1\n",
        "        self.in_size = in_size\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.look_back = look_back\n",
        "        self.lstm = nn.LSTM(in_size, self.n_hidden, n_layers, batch_first=True, dropout=0.3)\n",
        "        self.fc1 = nn.Linear(self.n_hidden*self.look_back, 1)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        # Forward propagate LSTM\n",
        "        y, (h, c) = self.lstm(x, h)\n",
        "        y = y.reshape(y.shape[0],-1)\n",
        "        out = self.fc1(y)\n",
        "        return out, (h, c)\n",
        "    \n",
        "    def init_hidden(self, bszh):\n",
        "        return (torch.zeros(self.n_layers, bszh, self.n_hidden), torch.zeros(self.n_layers, bszh, self.n_hidden)) \n",
        "\n",
        "# RNN Model Definition\n",
        "class Flu_RNN(nn.Module):\n",
        "    def __init__(self, in_size, n_hidden, look_back, n_layers=2):\n",
        "        super(Flu_RNN, self).__init__()\n",
        "        self.out = 1\n",
        "        self.in_size = in_size\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.look_back = look_back\n",
        "        self.rnn = nn.RNN(in_size, self.n_hidden, n_layers, batch_first=True, dropout=0.3)\n",
        "        self.fc1 = nn.Linear(self.n_hidden*self.look_back, 1)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        # Forward propagate\n",
        "        y, h = self.rnn(x, h)\n",
        "        y = y.reshape(y.shape[0],-1)\n",
        "        out = self.fc1(y)\n",
        "        return out, h\n",
        "    \n",
        "    def init_hidden(self, bszh):\n",
        "        return torch.zeros(self.n_layers, bszh, self.n_hidden) \n",
        "\n",
        "\n",
        "# GRU Model Definition\n",
        "class Flu_GRU(nn.Module):\n",
        "    def __init__(self, in_size, n_hidden, look_back, n_layers=2):\n",
        "        super(Flu_GRU, self).__init__()\n",
        "        self.out = 1\n",
        "        self.in_size = in_size\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.look_back = look_back\n",
        "        self.gru = nn.GRU(in_size, self.n_hidden, n_layers, batch_first=True, dropout=0.3)\n",
        "        self.fc1 = nn.Linear(self.n_hidden*self.look_back, 1)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        # Forward propagate\n",
        "        y, h = self.gru(x, h)\n",
        "        y = y.reshape(y.shape[0],-1)\n",
        "        out = self.fc1(y)\n",
        "        return out, h\n",
        "    \n",
        "    def init_hidden(self, bszh):\n",
        "        return torch.zeros(self.n_layers, bszh, self.n_hidden) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWm_YbMwRjhZ",
        "colab_type": "code",
        "outputId": "3d03a1e8-2c04-423d-d2ef-c881d98cd5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random\n",
        "\n",
        "look_back = 5\n",
        "bsz = 64\n",
        "epochs = 500\n",
        "n_hidden = 32\n",
        "years = []\n",
        "list_of_states = ['IN-TN', 'IN-KL', 'IN-KA', 'IN-AP', 'IN-GA', 'IN-MH','IN-CT','IN-OR','IN-MP','IN-GJ','IN-RJ','IN-UP','IN-JH','IN-WB','IN-BR','IN-HR','IN-PB','IN-HP','IN-JK','IN-UT','IN-SK','IN-ML','IN-AS','IN-AR','IN-NL','IN-MZ','IN-TR','IN-MN','IN-AN','IN-DL','IN-CH','IN-DD','IN-PY','IN-TG','IN-DN']\n",
        "\n",
        "start = 12\n",
        "end = 19\n",
        "all_states_performance = {}\n",
        "all_states_final = {}\n",
        "err = 1e-8\n",
        "key_word = 'flu'\n",
        "def detach(states):\n",
        "  if type(states) == tuple:\n",
        "    return [state.detach() for state in states]\n",
        "  else:\n",
        "    return states.detach()\n",
        "\n",
        "for j in range(len(list_of_states)):\n",
        "    # Feature scaling and pack data\n",
        "    sc = MinMaxScaler(feature_range = (0, 1))\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    loss_history = []\n",
        "    \n",
        "    # Pack data for LSTM\n",
        "    dataset_train = pd.read_csv(list_of_states[j] + str(start) + '_' + str(end-1) +'.csv')[key_word]\n",
        "    \n",
        "    training_set = dataset_train.values.reshape(-1,1)\n",
        "    for i in range(look_back, len(training_set)-1):\n",
        "        train_scaled = sc.fit_transform(training_set[i-look_back:i+1, 0].reshape(-1,1))\n",
        "        temp = train_scaled[:-1, 0].reshape(look_back , 1)\n",
        "        temp2 = train_scaled[-1, 0].reshape(1)\n",
        "        X_train.append(temp)\n",
        "        Y_train.append(temp2)\n",
        "        \n",
        "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    Y_train = np.reshape(Y_train, (Y_train.shape[0], Y_train.shape[1]))\n",
        "    z = torch.Tensor(X_train)\n",
        "    targets = torch.Tensor(Y_train)\n",
        "    \n",
        "    # Define model \n",
        "    #model = Flu_LSTM(1, n_hidden, look_back)\n",
        "    #model = Flu_GRU(1, n_hidden, look_back)\n",
        "    model = Flu_RNN(1, n_hidden, look_back)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Start training\n",
        "    for epoch in range(epochs):\n",
        "        # Set initial hidden and cell states\n",
        "        hidden = model.init_hidden(bsz)\n",
        "    \n",
        "        # Get mini-batch inputs and targets\n",
        "        indx = np.random.randint(X_train.shape[0], size=bsz)\n",
        "        inputs = z[indx,:,:]\n",
        "        target = targets[indx,:]\n",
        "    \n",
        "        # Forward pass\n",
        "        hidden = detach(hidden)\n",
        "        y, hidden = model.forward(inputs, hidden)\n",
        "        loss = criterion(target, y)\n",
        "    \n",
        "        # Backward and optimize\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_history.append(loss)\n",
        "        if epoch%50==0: \n",
        "            print (epoch, loss)\n",
        "\n",
        "    plt.plot(loss_history)\n",
        "    plt.xlabel('Iter')\n",
        "    plt.ylabel('Loss')\n",
        "    #plt.savefig(r'' + 'loss_' + list_of_states[j] + str(start) + '_' + str(end-1) + '.jpg')\n",
        "    plt.show()\n",
        "    \n",
        "    #start test loop\n",
        "    X_test = []\n",
        "    Y_test = []\n",
        "    Y_random = []\n",
        "    # dataset_test = pd.read_csv(r'./data_flu/'+ list_of_states[j] + str(end) +'.csv')[key_word]\n",
        "    dataset_test = pd.read_csv(list_of_states[j] + str(end) +'.csv')[key_word]\n",
        "\n",
        "    test_set = dataset_test.values.reshape(-1,1)\n",
        "    for i in range(look_back, len(test_set)):\n",
        "        test_scaled = sc.fit_transform(test_set[i-look_back:i, 0].reshape(-1,1))\n",
        "        temp = test_scaled[:, 0].reshape(look_back, 1)\n",
        "        test_scaled1 = sc.fit_transform(test_set[i-look_back:i+1, 0].reshape(-1,1))\n",
        "        temp2 = test_scaled1[:, 0].reshape(-1)\n",
        "        temp3 = np.array(random.random()).reshape(1)\n",
        "        X_test.append(temp)\n",
        "        Y_test.append(temp2)\n",
        "        Y_random.append(temp3)\n",
        "    \n",
        "    model.eval()   \n",
        "    X_test = np.array(X_test)\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "    real = np.array(Y_test)\n",
        "    Y_random = np.array(Y_random)\n",
        "    X_test = torch.Tensor(X_test)\n",
        "    hidden = model.init_hidden(int(X_test.shape[0]))\n",
        "    hidden = detach(hidden)\n",
        "    y, _ = model.forward(X_test, hidden)\n",
        "    y = np.array(y.detach())\n",
        "    predicted = np.concatenate((X_test.reshape(X_test.shape[0],X_test.shape[1]),y),axis=1)\n",
        "    rand = np.concatenate((X_test.reshape(X_test.shape[0],X_test.shape[1]),Y_random),axis=1)\n",
        "    \n",
        "    total_r_s = []\n",
        "    total_r_s_rank_predicted = []\n",
        "    total_r_s_rank_real = []\n",
        "    \n",
        "    total_r_s_1 = []\n",
        "    total_r_s_1_pvalue = []\n",
        "    \n",
        "    total_r_s_1_r = []\n",
        "    total_r_s_1_pvalue_r = []\n",
        "    \n",
        "    total_c_c = []\n",
        "    total_c_c_r = []\n",
        "    \n",
        "    for i in range(real.shape[0]):\n",
        "        predicted_rank = stats.rankdata(predicted[i], method='average')\n",
        "        real_rank = stats.rankdata(real[i], method='average')\n",
        "        total_r_s_rank_predicted.append(predicted_rank)\n",
        "        total_r_s_rank_real.append(real_rank)\n",
        "        n = real.shape[1]\n",
        "        diffs = real_rank - predicted_rank\n",
        "        r_s = 1 - 6*sum(diffs*diffs)/(n*(n**2 - 1))\n",
        "        r_s_1, p_value = stats.spearmanr(real[i]+err, predicted[i]+2*err)\n",
        "        r_s_1_r, p_value_r = stats.spearmanr(real[i]+err, rand[i]+2*err)\n",
        "        c_c = np.corrcoef(real[i]+err, predicted[i]+2*err)[0,1]\n",
        "        c_c_r = np.corrcoef(real[i]+err, rand[i]+2*err)[0,1]\n",
        "        total_r_s.append(r_s)\n",
        "        total_r_s_1.append(r_s_1)\n",
        "        total_r_s_1_pvalue.append(p_value)\n",
        "        total_r_s_1_r.append(r_s_1_r)\n",
        "        total_r_s_1_pvalue_r.append(p_value_r)\n",
        "        total_c_c.append(c_c)\n",
        "        total_c_c_r.append(c_c_r)\n",
        "    \n",
        "    avg_r_s = np.array(total_r_s).mean()\n",
        "    avg_r_s_1 = np.array(total_r_s_1).mean()\n",
        "    avg_r_s_1_pvalue = np.array(total_r_s_1_pvalue).mean()\n",
        "    avg_r_s_1_r = np.array(total_r_s_1_r).mean()\n",
        "    avg_r_s_1_pvalue_r = np.array(total_r_s_1_pvalue_r).mean()\n",
        "    avg_c_c = np.array(total_c_c).mean()\n",
        "    avg_c_c_r = np.array(total_c_c_r).mean()\n",
        "    print('The average Spearman Rank Coefficient is:', avg_r_s)\n",
        "    print('The average Spearman Rank Coefficient_1 is:', avg_r_s_1, 'with p_value of:', avg_r_s_1_pvalue)\n",
        "    print('The average Correlation Coefficient is:', avg_c_c)\n",
        "    print('The average Spearman Rank Coefficient (random) is:', avg_r_s)\n",
        "    print('The average Spearman Rank Coefficient_1 (random) is:', avg_r_s_1_r, 'with p_value of:', avg_r_s_1_pvalue_r)\n",
        "    print('The average Correlation Coefficient (random) is:', avg_c_c_r)\n",
        "    #pd.DataFrame(predicted).to_csv(r'' + list_of_states[j] + str(end) + 'predicted'+'.csv')\n",
        "    all_states_performance[list_of_states[j]] = [avg_r_s_1, avg_r_s_1_pvalue, avg_c_c, avg_r_s_1_r, avg_r_s_1_pvalue_r, avg_c_c_r]\n",
        "    \n",
        "    final_x_scaled = sc.fit_transform(test_set[len(test_set)-look_back:len(test_set), 0].reshape(-1,1))\n",
        "    temp = final_x_scaled[:, 0].reshape(look_back, 1)\n",
        "    temp1 = torch.Tensor(temp).reshape(1,-1,1)\n",
        "    hidden = model.init_hidden(int(temp1.shape[0]))\n",
        "    hidden = detach(hidden)\n",
        "    final_y, _ = model.forward(temp1, hidden)\n",
        "    final_y = np.array(final_y.detach())\n",
        "    final = np.concatenate((np.transpose(temp), final_y),axis=1)\n",
        "    all_states_final[list_of_states[j]] = final.reshape(-1)*100\n",
        "\n",
        "all_states_performance = pd.DataFrame.from_dict(all_states_performance, orient='index', columns=['SRCorr', 'SR_pvalue', 'Corr','SRCorr (r)', 'SR_pvalue(r)', 'Corr(r)'])\n",
        "all_states_performance.to_csv(r'' + 'all_' + str(end) + 'predicted_performances'+'.csv')\n",
        "\n",
        "all_states_final = pd.DataFrame.from_dict(all_states_final, orient='index')\n",
        "all_states_final.to_csv(r'' + 'all_' + str(end) + 'predicted_final'+'.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.3453, grad_fn=<MeanBackward0>)\n",
            "50 tensor(0.0918, grad_fn=<MeanBackward0>)\n",
            "100 tensor(0.0509, grad_fn=<MeanBackward0>)\n",
            "150 tensor(0.0714, grad_fn=<MeanBackward0>)\n",
            "200 tensor(0.0703, grad_fn=<MeanBackward0>)\n",
            "250 tensor(0.0683, grad_fn=<MeanBackward0>)\n",
            "300 tensor(0.0591, grad_fn=<MeanBackward0>)\n",
            "350 tensor(0.0761, grad_fn=<MeanBackward0>)\n",
            "400 tensor(0.0674, grad_fn=<MeanBackward0>)\n",
            "450 tensor(0.0733, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURQlFBUIRVEUJZT/D4M8utAeC9TCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-401e4628c760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0dea5c48d3c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [37 x 160], m2: [640 x 1] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:197"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWpun2b8g7Bf",
        "colab_type": "text"
      },
      "source": [
        "# **6. Testing and Analysing of the Results**\n",
        "*   The prediction is tested on the test set that the model has not seen before for the year 2019\n",
        "*   As we are interested in measuring how well the predicted 6th week fits the trend relaive to the past 5 weeks, we use the Pearson correlation coefficient instead of MSE\n",
        "\n",
        " >$pearson = \\frac{{}\\sum_{i=1}^{n} (x_i - \\overline{x})(y_i - \\overline{y})}\n",
        "{\\sqrt{\\sum_{i=1}^{n} (x_i - \\overline{x})^2(y_i - \\overline{y})^2}}$\n",
        "\n",
        " *where $x_i$, $y_i$ are the 2 sets of data and n is the number of data points*\n",
        "\n",
        "*   The correlation coefficient is measured between the predicted trend and the true trend for the 6 weeks period and averaged out across the test set for each Indian state\n",
        "*   MSE may not serve the best purpose here since we care more about relative trends within the 6 weeks window and also because of the lack of absolute values to compare against\n",
        "*   In addition, we added the Spearman rank coefficients which is scale agnostic for measuring the correlation more accurately:\n",
        "\n",
        " >$spearman = 1- {\\frac {6 \\sum d_i^2}{n(n^2 - 1)}}$\n",
        "\n",
        "  *where d is the pairwise rank differences between the two set of data and n is the number of data points*\n",
        "\n",
        "*   The predicted values here are nothing but relatives to the past 5 weeks\n",
        "*   To avoid look ahead bias, the min-max scaling here is done only on the 5 weeks of inputs (in contrast to how it was done in the train set)\n",
        "*   To further show that our model actually picks up interesting trends, we compare the performance with an untrained random neural network model\n",
        "*   If our models perform better than the untrained random neural network, we can conclude reasonably that the training process was effective and that the network picked up some statistical relationship\n",
        "*   We showed that all 3 of our models are better than an untrained random model(r) in terms of the Pearson and Spearman rank coefficients\n",
        "\n",
        "\n",
        "|Model| SRCorr|SR_pvalue|Corr|SRCorr(r)|SR_pvalue(r)|Corr(r)| \n",
        "|------| ------------- |---------------| ------|------------- |---------------| ------|\n",
        "|LSTM| 0.842922|0.070021|0.850378|0.805962 |0.094018 |0.803782 |\n",
        "|GRU| 0.841829|0.069762|0.851068|0.806070|0.094747|0.804042 |\n",
        "|RNN| 0.842005|0.071110|0.850333|0.800184|0.099372|0.795190 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do8dpE6g0Zm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "all_states_performance_filtered = pd.read_csv('all_19predicted_performances.csv').dropna()\n",
        "all_states_performance_filtered_avg = all_states_performance_filtered.describe()\n",
        "print(all_states_performance_filtered_avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozjpWT0QXK2r",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}